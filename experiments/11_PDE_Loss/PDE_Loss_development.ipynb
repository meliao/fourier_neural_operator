{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8665f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# import torch.fft as fft\n",
    "from torch.nn.parameter import Parameter\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "# import h5py\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "from timeit import default_timer\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b2fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpectralConv1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1):\n",
    "        super(SpectralConv1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        1D Fourier layer. It does FFT, linear transform, and Inverse FFT.\n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1  #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "\n",
    "        self.scale = (1 / (in_channels*out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, dtype=torch.cfloat))\n",
    "\n",
    "    # Complex multiplication\n",
    "    def compl_mul1d(self, input, weights):\n",
    "        # (batch, in_channel, x ), (in_channel, out_channel, x) -> (batch, out_channel, x)\n",
    "        return torch.einsum(\"bix,iox->box\", input, weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.fft.rfft(x)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.out_channels, x.size(-1)//2 + 1,  device=x.device, dtype=torch.cfloat)\n",
    "        out_ft[:, :, :self.modes1] = self.compl_mul1d(x_ft[:, :, :self.modes1], self.weights1)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.fft.irfft(out_ft, n=x.size(-1))\n",
    "        return x\n",
    "\n",
    "\n",
    "class FNO1dComplexTime(nn.Module):\n",
    "    def __init__(self, modes, width):\n",
    "        super(FNO1dComplexTime, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "\n",
    "        input: the solution of the initial condition and location (Re(a(x)), Im(a(x)), x)\n",
    "        input shape: (batchsize, x=s, c=3)\n",
    "        output: the solution of a later timestep\n",
    "        output shape: (batchsize, x=s, c=2)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes\n",
    "        self.width = width\n",
    "        self.fc0 = nn.Linear(4, self.width) # input channel is 3: (Re(a(x)), Im(a(x)), x, t)\n",
    "\n",
    "        self.conv0 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.conv1 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.conv2 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.conv3 = SpectralConv1d(self.width, self.width, self.modes1)\n",
    "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # print(\"INPUT X SHAPE: {} DTYPE: {}\".format(x.shape, x.dtype))\n",
    "        # print(\"INPUT T SHAPE: {} DTYPE: {}\".format(t.shape, t.dtype))\n",
    "        # print(\"T: {}\".format(t))\n",
    "        t = t.view(-1, 1, 1).repeat([1, x.shape[1], 1])\n",
    "        # print(\"T0: {}\".format(t[0]))\n",
    "        # print(\"T1: {}\".format(t[1]))\n",
    "        # print(\"INPUT T SHAPE: {} DTYPE: {}\".format(t.shape, t.dtype))\n",
    "        # o = torch.ones((1,  x.size()[1]), dtype = torch.float)\n",
    "        # print(\"INPUT O SHAPE: {} DTYPE: {}\".format(o.shape, o.dtype))\n",
    "        # t_arr = torch.matmul(t,  o)\n",
    "        # print(\"T_ARR SHAPE: {}\".format(t_arr.shape))\n",
    "        x = torch.cat([x, t], dim=2)\n",
    "        # print(\"X SHAPE: {}\".format(x.shape))\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x)\n",
    "\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return torch.view_as_complex(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71dff4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLS_Residual_Loss:\n",
    "    \"\"\"\n",
    "    NLS: i u_t + 1 / 2 * u_xx + |u|^2 u = 0\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, delta_x, delta_t, n_grid_points):\n",
    "        self.delta_x = delta_x\n",
    "        self.delta_t = delta_t\n",
    "        self.n_grid_points = n_grid_points\n",
    "        # self.batch_size = batch_size\n",
    "        # self.I = torch.eye(self.batch_size)\n",
    "        # self.imag = torch.tensor(0+1j, dtype=torch.cfloat).repeat((self.batch_size, self.n_grid_points))\n",
    "\n",
    "\n",
    "    def time_derivative(self, model, x, t):\n",
    "        \"\"\"\n",
    "        u_t ~= (u(x, t + delta_t) - u(x, t)) / delta_t\n",
    "        \"\"\"\n",
    "        term_1 = model(x,t)\n",
    "        t_advance = t + self.delta_t\n",
    "        term_2 = model(x, t_advance)\n",
    "        out = torch.div(term_2 - term_1, self.delta_t)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def spatial_discrete_derivatives(self, u):\n",
    "        u_shift_right = torch.roll(u, 1, 1)\n",
    "        u_shift_left = torch.roll(u, -1, 1)\n",
    "        \n",
    "        u_xx = (u_shift_left  - 2*u + u_shift_right) / (self.delta_x ** 2)\n",
    "        return u_xx\n",
    "        \n",
    "    def __call__(self, model, x, t):\n",
    "        # x has shape (batch_size, s, 3)\n",
    "        # u has shape (batch_size, s, 1)\n",
    "        return self.NLS_residual(model, x, t)\n",
    "\n",
    "    def NLS_residual(self, model, x, t):\n",
    "        u = model(x,t)\n",
    "\n",
    "        u_abs = torch.mul(u, torch.square(torch.abs(u)))\n",
    "        u_t = self.time_derivative(model, x, t)\n",
    "        u_xx = self.spatial_discrete_derivatives(u)\n",
    "\n",
    "        resid = torch.mul(u_t, 0+1j) + torch.mul(u_xx, 1/2) + u_abs\n",
    "\n",
    "        return torch.square(resid.abs()).sum()        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e98ae83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FP = '/local/meliao/projects/fourier_neural_operator/data/2021-06-11_NLS_data_02/NLS_data_seed_0.mat'\n",
    "MODEL_FP = '/local/meliao/projects/fourier_neural_operator/experiments/08_FNO_pretraining/models/00_pretrain_ep_1000'\n",
    "PLOTS_DIR = '/local/meliao/projects/fourier_neural_operator/experiments/11_PDE_Loss/superresolution_plots'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "30d6c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sio.loadmat(DATA_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8da26422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeModel:\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.tensor(X)\n",
    "    def __call__(self, x, t):\n",
    "        t_idx = t / 0.001\n",
    "        return self.X[4, int(t_idx)].view((1,1024))\n",
    "\n",
    "\n",
    "class ConstantFakeModel:\n",
    "    def __init__(self, a):\n",
    "        self.out = torch.mul(torch.ones((1,1024), dtype=torch.cdouble), a)\n",
    "    def __call__(self,x,t):\n",
    "        return self.out\n",
    "def prepare_input(X):\n",
    "    # X has shape (nbatch, 1, grid_size)\n",
    "    s = X.shape[-1]\n",
    "    n_batches = X.shape[0]\n",
    "\n",
    "    # Convert to tensor\n",
    "    X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
    "\n",
    "    # FNO code appends the spatial grid to the input as below:\n",
    "    x_grid = torch.linspace(-np.pi, np.pi, s).view(-1,1)\n",
    "    X_input = torch.cat((X_input, x_grid.repeat(n_batches, 1, 1)), axis=2)\n",
    "\n",
    "    return X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "FNO1dComplexTime(\n  (fc0): Linear(in_features=4, out_features=64, bias=True)\n  (conv0): SpectralConv1d()\n  (conv1): SpectralConv1d()\n  (conv2): SpectralConv1d()\n  (conv3): SpectralConv1d()\n  (w0): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n  (w1): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n  (w2): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n  (w3): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n  (fc1): Linear(in_features=64, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=2, bias=True)\n)"
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "fake_model_1 = FakeModel(d['output'])\n",
    "fake_model_2 = ConstantFakeModel(0.)\n",
    "real_model = torch.load(MODEL_FP, map_location='cpu')\n",
    "real_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj = NLS_Residual_Loss(2 * np.pi / 1024, 0.001, 1024 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 1024, 3])\n939334.75 0.10543419700115919\n935120.75 0.06653134804219007\n926235.25 0.08486056001856923\n917506.0 0.0825958059867844\n908060.0 0.06718615198042244\n902314.0 0.07377398200333118\n900137.25 0.08174675796180964\n906817.0625 0.07045507500879467\n910318.0 0.07308840204495937\n910994.25 0.08237527508754283\n"
    }
   ],
   "source": [
    "aa = fake_model_1.X[:1,0]\n",
    "x_input = prepare_input(aa)\n",
    "print(x_input.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    t = torch.tensor(i * 0.001)\n",
    "    t0 = default_timer()\n",
    "\n",
    "    v = loss_obj(real_model, x_input, t)\n",
    "    v.backward()\n",
    "    t1 = default_timer()\n",
    "    print(v.item(), t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}