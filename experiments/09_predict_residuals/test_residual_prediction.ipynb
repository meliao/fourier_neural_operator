{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "/local/meliao/projects/fourier_neural_operator/experiments/09_predict_residuals\n"
    }
   ],
   "source": [
    "WD = '/local/meliao/projects/fourier_neural_operator/experiments/09_predict_residuals/'\n",
    "os.chdir(WD)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_models import SpectralConv1d, FNO1dComplexTime, TimeDataSetResiduals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = '/local/meliao/projects/fourier_neural_operator/experiments/09_predict_residuals/results/00_residual_train.txt'\n",
    "TEST_DF = '/local/meliao/projects/fourier_neural_operator/experiments/09_predict_residuals/results/00_residual_test.txt'\n",
    "DATA_FP = '/local/meliao/projects/fourier_neural_operator/data/2021-06-24_NLS_data_04_test.mat'\n",
    "MODEL_FP = '/local/meliao/projects/fourier_neural_operator/experiments/09_predict_residuals/models/00_residual_ep_500'\n",
    "BASELINE_FP = '/local/meliao/projects/fourier_neural_operator/experiments/08_FNO_pretraining/models/00_pretrain_ep_1000'\n",
    "# PLOTS_DIR = '/local/meliao/projects/fourier_neural_operator/experiments/09_predict_residuals/plots/'\n",
    "PLOTS_DIR = 'plots/'\n",
    "RESULTS_DIR = 'results/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_table(TRAIN_DF)\n",
    "test_df = pd.read_table(TEST_DF)\n",
    "fp_train_test = os.path.join(PLOTS_DIR, 'first_train_test.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_plot(a_train, a_test, fp=None, title=\"\"):\n",
    "    fig, ax = plt.subplots(1, 2, sharey=False)\n",
    "    fig.patch.set_facecolor('white')\n",
    "#     fig.set_size_inches(6.4, 5.2)\n",
    "\n",
    "\n",
    "    # a_train and a_test are the time-dependent FNO data. They're in the first column\n",
    "    ax[0].set_title(\"Train\")\n",
    "    ax[0].plot(a_train.epoch, a_train.MSE, '-', color='red', label='train')\n",
    "    ax[1].plot(a_test.epoch, a_test.test_mse, '--', color='red', label='test')\n",
    "    ax[0].set_xlabel(\"Epoch\", fontsize=13)\n",
    "    ax[1].set_xlabel(\"Epoch\", fontsize=13)\n",
    "    # ax[0].legend()\n",
    "    ax[0].set_yscale('log')\n",
    "\n",
    "    ax[0].set_ylabel(\"MSE\", fontsize=13)\n",
    "\n",
    "    # b_train and b_test are the time-dependent. They're in the seecond column\n",
    "    ax[1].set_title(\"Test\")\n",
    "    # ax[1].plot(b_train.epoch, b_train.MSE, '-', color='blue', label='train')\n",
    "    # ax[1].plot(b_test.epoch, b_test.test_mse, '--', color='blue', label='test')\n",
    "    ax[1].set_xlabel(\"Epoch\", fontsize=13)\n",
    "    ax[1].set_yscale('log')\n",
    "    # ax[1].legend(fontsize=13)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "\n",
    "\n",
    "    if fp is not None:\n",
    "        plt.savefig(fp)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WORKING ON residuals_lr_exp_-1.5_l2_exp_-2\n{'min_test_error': 0.9546307127518185, 'lr_exp': -1.5, 'l2_exp': -2.0}\nWORKING ON residuals_lr_exp_-1.5_l2_exp_-1\n{'min_test_error': 0.1203479484678551, 'lr_exp': -1.5, 'l2_exp': -1.0}\nWORKING ON residuals_lr_exp_-0.5_l2_exp_-1\n{'min_test_error': 45894.14647161016, 'lr_exp': -0.5, 'l2_exp': -1.0}\nWORKING ON residuals_lr_exp_-2_l2_exp_1\n{'min_test_error': 0.11890807563634742, 'lr_exp': -2.0, 'l2_exp': 1.0}\nWORKING ON residuals_lr_exp_-1.5_l2_exp_-5\n{'min_test_error': 0.1690894309840027, 'lr_exp': -1.5, 'l2_exp': -5.0}\nWORKING ON residuals_lr_exp_-0.5_l2_exp_0\n{'min_test_error': 1676829.2165497874, 'lr_exp': -0.5, 'l2_exp': 0.0}\nWORKING ON residuals_lr_exp_-3_l2_exp_-5\n{'min_test_error': 0.12267313356680216, 'lr_exp': -3.0, 'l2_exp': -5.0}\nWORKING ON residuals_lr_exp_-2.5_l2_exp_-0.5\n{'min_test_error': 0.11891345250346379, 'lr_exp': -2.5, 'l2_exp': -0.5}\nWORKING ON residuals_lr_exp_-0.5_l2_exp_-3\n{'min_test_error': 46275736.61305666, 'lr_exp': -0.5, 'l2_exp': -3.0}\nWORKING ON residuals_lr_exp_-3_l2_exp_-4\n{'min_test_error': 0.12739978292686224, 'lr_exp': -3.0, 'l2_exp': -4.0}\nWORKING ON residuals_lr_exp_-2_l2_exp_-1.5\n{'min_test_error': 0.11891486246112623, 'lr_exp': -2.0, 'l2_exp': -1.5}\nWORKING ON residuals_lr_exp_-3_l2_exp_-0.5\n{'min_test_error': 0.11893246633290036, 'lr_exp': -3.0, 'l2_exp': -0.5}\nWORKING ON residuals_lr_exp_-5_l2_exp_1\n{'min_test_error': 0.11963148094838934, 'lr_exp': -5.0, 'l2_exp': 1.0}\nWORKING ON residuals_lr_exp_-2.5\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-4dd0bc75f334>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdd_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'min_test_error'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_test_i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0msearch_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_re\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdd_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr_exp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mdd_i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l2_exp'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "# TRAIN_PATTERN = \"/local/meliao/projects/fourier_neural_operator/experiments/09_predict_residuals/results/residuals_lr_exp_{}_train.txt\"\n",
    "# TEST_PATTERN = \"/local/meliao/projects/fourier_neural_operator/experiments/09_predict_residuals/results/residuals_lr_exp_{}_test.txt\"\n",
    "# for i in [-5, -4, -3, -2.5, -2, -2.5, -1, -0.5, 0, 1]:\n",
    "#     df_test_i = pd.read_table(TEST_PATTERN.format(i))\n",
    "#     df_train_i = pd.read_table(TRAIN_PATTERN.format(i))\n",
    "#     fp_out_i = os.path.join(PLOTS_DIR, 'train_test_{}.png'.format(i))\n",
    "#     t = \"Learning Rate: 10e{}\".format(i)\n",
    "#     make_train_test_plot(df_train_i, df_test_i, fp=fp_out_i, title=t)\n",
    "\n",
    "results_lst = []\n",
    "res_re = re.compile(\"residuals_lr_exp_(.*)_l2_exp_(.*)\")\n",
    "for f in os.listdir(RESULTS_DIR):\n",
    "    if not f.endswith(\"_train.txt\"):\n",
    "        continue\n",
    "    else:\n",
    "        fname = f.rstrip(\"_train.txt\")\n",
    "        print(\"WORKING ON\", fname)\n",
    "        fp_train = os.path.join(RESULTS_DIR, fname + \"_train.txt\")\n",
    "        fp_test = os.path.join(RESULTS_DIR, fname + \"_test.txt\")\n",
    "        title = fname.split('/')[-1]\n",
    "        df_train_i = pd.read_table(fp_train)\n",
    "        df_test_i = pd.read_table(fp_test)\n",
    "        \n",
    "        # Find min test error\n",
    "        dd_i = {}\n",
    "        dd_i['min_test_error'] = df_test_i.test_mse.mean()\n",
    "        search_obj = res_re.search(title)\n",
    "        dd_i['lr_exp'] = float(search_obj.group(1))\n",
    "        dd_i['l2_exp'] = float(search_obj.group(2))\n",
    "        \n",
    "        # Make plot of train/test errors\n",
    "        fp_out_train_test_plot = os.path.join(PLOTS_DIR, \"train_test_\" + title + \".png\")\n",
    "        plt_title = \"LR=10e{}, L2 Reg=10e{}\".format(dd_i['lr_exp'], dd_i['l2_exp'])\n",
    "        make_train_test_plot(df_train_i, df_test_i, fp=fp_out_train_test_plot, title=plt_title)\n",
    "        \n",
    "\n",
    "        print(dd_i)\n",
    "        # Save result into a list of dictionaries\n",
    "        results_lst.append(dd_i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2_exp      -5.0      -4.0      -3.0      -2.5      -2.0      -1.5      -1.0  \\\n",
      "lr_exp                                                                         \n",
      "-5.0    0.119486  0.119376  0.119102  0.118997  0.118961  0.118978  0.119099   \n",
      "-4.0    0.137302  0.132764  0.118929  0.118910  0.118909  0.118921  0.118923   \n",
      "-3.0    0.122673  0.127400  0.118916  0.118916  0.118919  0.118921  0.118926   \n",
      "-2.5    0.161237  0.132557  0.118911  0.118914  0.118913  0.118920  0.118920   \n",
      "-2.0    0.119129  0.119406  0.132846  0.119317  0.124401  0.118915  0.118910   \n",
      "\n",
      "l2_exp      -0.5       0.0       1.0  \n",
      "lr_exp                                \n",
      "-5.0    0.119264  0.119419  0.119631  \n",
      "-4.0    0.118926  0.118933  0.118952  \n",
      "-3.0    0.118932  0.118935  0.118942  \n",
      "-2.5    0.118913  0.118907  0.118906  \n",
      "-2.0    0.118920  0.118909  0.118908  \n"
     ]
    }
   ],
   "source": [
    "r_df = pd.DataFrame(results_lst).pivot(index='lr_exp', columns='l2_exp', values='min_test_error')\n",
    "print(r_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(values, vals_y, label_y, vals_x, label_x, title, cbarlabel='', fp=None):\n",
    "    # l1_axis = np.unique(lambda_1) #Lambda 1 on vertical\n",
    "    # l2_axis = np.unique(lambda_2) #Lambda 2 on horizontal\n",
    "    # values_arr = values.reshape((l1_axis.shape[0], l2_axis.shape[0]))\n",
    "#     values = np.log10(values)\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(values, origin='lower')\n",
    "    ax.set_xticks([i for i in range(vals_x.shape[0])])\n",
    "    ax.set_xticklabels(vals_x)\n",
    "    # ax.set_xticklabels([\"{:.2f}\".format(i) for i in l2_axis])\n",
    "    ax.set_xlabel(label_x, size=14)\n",
    "    ax.set_yticks([i for i in range(vals_y.shape[0])])\n",
    "    ax.set_yticklabels(vals_y)\n",
    "    # ax.set_yticklabels([\"{:.2f}\".format(i) for i in l1_axis])\n",
    "    ax.set_ylabel(label_y, size=14)\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    cbar.set_label(cbarlabel)\n",
    "    # plt.tight_layout()\n",
    "    plt.title(title)\n",
    "    if fp is not None:\n",
    "        plt.savefig(fp)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "r_df = r_df[r_df.index < -1.5]\n",
    "r_df = r_df[[-2., -1.5, -1.0, -0.5, 0., 1.]]\n",
    "\n",
    "fp_heatmap=os.path.join(PLOTS_DIR, 'heatmap_TDRP_test_errors.png')\n",
    "plot_heatmap(r_df.values,\n",
    "            vals_y=r_df.index.values,\n",
    "            label_y='$log_{10}$(Learning Rate)',\n",
    "            vals_x=r_df.columns.values,\n",
    "            label_x='$log_{10}$(L2 reg.)',\n",
    "            title='TDRP test error',\n",
    "            cbarlabel='min test error',\n",
    "            fp=fp_heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DF = 'results/residuals_lr_exp_-3_l2_exp_1_test.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    epoch  test_l2_normalized_error  test_mse\n",
      "16    800                  0.287336  0.118325\n",
      "17    850                  0.287480  0.118507\n",
      "18    900                  0.287998  0.118624\n",
      "12    600                  0.287853  0.118632\n",
      "2     100                  0.287909  0.118643\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_table(TEST_DF)\n",
    "test_df = test_df.sort_values('test_mse')\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FP = 'models/residuals_lr_exp_-3_l2_exp_1_ep_800'\n",
    "DATA_FP = '/home/owen/projects/fourier_neural_operator/data/2021-06-24_NLS_data_04_test.mat'\n",
    "BASELINE_FP = '/home/owen/projects/fourier_neural_operator/experiments/08_FNO_pretraining/models/00_pretrain_ep_1000'\n",
    "\n",
    "# DATA_FP = '/local/meliao/projects/fourier_neural_operator/data/2021-06-24_NLS_data_04_test.mat'\n",
    "# MODEL_FP = '/local/meliao/projects/fourier_neural_operator/experiments/09_predict_residuals/models/00_residual_ep_500'\n",
    "# BASELINE_FP = '/local/meliao/projects/fourier_neural_operator/experiments/08_FNO_pretraining/models/00_pretrain_ep_1000'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_train_test_plot(train_df, test_df, fp=fp_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sio.loadmat(DATA_FP)\n",
    "model = torch.load(MODEL_FP, map_location='cpu')\n",
    "emulator = torch.load(BASELINE_FP, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t_tensor = torch.tensor(t_interval, dtype=torch.float).repeat([self.n_batches, 1,1])\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n"
     ]
    }
   ],
   "source": [
    "t_dset = TimeDataSetResiduals(d['output'][:, :7], d['t'][:, :7], d['x'], emulator)\n",
    "t_dloader = torch.utils.data.DataLoader(t_dset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_check(x, y, t, preds, resid, fp=None):\n",
    "\n",
    "    # X has size (grid_size, 3) with the columns being (Re(u_0), Im(u_0), x)\n",
    "    fig, ax=plt.subplots(nrows=1, ncols=4)\n",
    "    fig.set_size_inches(15,10) #15, 20 works well\n",
    "    fig.patch.set_facecolor('white')\n",
    "\n",
    "    x_real = x[:, 0].flatten()\n",
    "    x_imag = x[:, 1].flatten()\n",
    "    # print(\"X_REAL:\", x_real.shape, \"X_IMAG:\", x_imag.shape)\n",
    "    # print(\"PREDS_REAL:\", np.real(preds).shape, \"PREDS_IMAG:\", np.imag(preds).shape)\n",
    "    # print(\"Y_REAL:\", np.real(y).shape, \"Y_IMAG:\", np.imag(y).shape)\n",
    "\n",
    "    ax[0].set_title(\"$Re(u)$\")\n",
    "    ax[0].plot(x_real, label='Input')\n",
    "    ax[0].plot(np.real(y), label='Soln') \n",
    "    ax[0].plot(np.real(preds), '--', label='Pred')\n",
    "\n",
    "    ax[0].legend()  \n",
    "\n",
    "    ax[1].set_title(\"Residuals: $Re(u)$\")\n",
    "    ax[1].plot(np.real(y) - np.real(preds), color='red', label='actual')\n",
    "    ax[1].plot(np.real(resid), color='green', label='predicted')\n",
    "    ax[1].legend()\n",
    "    \n",
    "    ax[2].set_title(\"$Im(u)$\")\n",
    "    ax[2].plot(x_imag, label='Input')\n",
    "    ax[2].plot(np.imag(y), label='Soln')\n",
    "    ax[2].plot(np.imag(preds), '--', label='Pred')\n",
    "    ax[2].legend()\n",
    "\n",
    "    ax[3].set_title(\"Residuals: $Im(u)$\")\n",
    "\n",
    "    ax[3].plot(np.imag(y) - np.imag(preds), color='red', label='actual')\n",
    "    ax[3].plot(np.imag(resid), color='green', label='predicted')\n",
    "\n",
    "    ax[3].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # plt.title(\"T = {}\".format(t))\n",
    "    if fp is not None:\n",
    "        plt.savefig(fp)\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(MODEL_FP, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
      "/home/owen/projects/fourier_neural_operator/experiments/09_predict_residuals/train_models.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 0\n",
    "for x_i, y_i, t_i, preds_i in t_dloader:\n",
    "    # x_i, y_i, t_i, preds_i = t_dset[i]\n",
    "    # print(x_i.shape)\n",
    "    model_resid = model(x_i, t_i)\n",
    "    fp_i = os.path.join(PLOTS_DIR, 'test_case_{}.png'.format(n))    \n",
    "    plot_check(x_i[0], y_i[0], t_i.item(), preds_i[0], model_resid[0].detach().numpy(), fp=fp_i)\n",
    "    n += 1\n",
    "    if n >= 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fp):\n",
    "    logging.info(\"Loading data from {}\".format(fp))\n",
    "    data = sio.loadmat(os.path.expanduser(fp))\n",
    "    return data['output'], data['t']\n",
    "\n",
    "def load_model(fp, device):\n",
    "    # Model datatypes are loaded from train_models.py\n",
    "    model = torch.load(fp, map_location=device)\n",
    "    return model\n",
    "\n",
    "def l2_normalized_error(pred, actual):\n",
    "    \"\"\"Short summary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : type\n",
    "        Description of parameter `pred`.\n",
    "    actual : type\n",
    "        Description of parameter `actual`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    types\n",
    "        Description of returned object.\n",
    "\n",
    "    \"\"\"\n",
    "    errors = pred - actual\n",
    "    error_norms = torch.linalg.norm(torch.tensor(errors), dim=-1, ord=2)\n",
    "    actual_norms = torch.linalg.norm(torch.tensor(actual), dim=-1, ord=2)\n",
    "    normalized_errors = torch.divide(error_norms, actual_norms)\n",
    "    return normalized_errors.detach().numpy()\n",
    "def prepare_input(X):\n",
    "    # X has shape (nbatch, 1, grid_size)\n",
    "    s = X.shape[-1]\n",
    "    n_batches = X.shape[0]\n",
    "\n",
    "    # Convert to tensor\n",
    "    X_input = torch.view_as_real(torch.tensor(X, dtype=torch.cfloat))\n",
    "\n",
    "    # FNO code appends the spatial grid to the input as below:\n",
    "    x_grid = torch.linspace(-np.pi, np.pi, 1024).view(-1,1)\n",
    "    X_input = torch.cat((X_input, x_grid.repeat(n_batches, 1, 1)), axis=2)\n",
    "\n",
    "    return X_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_TDRP_predictions(X, t_grid, model, emulator):\n",
    "\n",
    "    # X has shape (nbatch, n_tsteps, grid_size)\n",
    "    TEST_KEYS = ['TDRP', 'FNO']\n",
    "    preds_dd = {i: np.zeros((X.shape[0], X.shape[1]-1, X.shape[2]), dtype=np.cdouble) for i in TEST_KEYS}\n",
    "    errors_dd = {i: np.zeros((X.shape[0], X.shape[1]-1), dtype=np.double) for i in TEST_KEYS}\n",
    "\n",
    "    one_tensor = torch.tensor(1, dtype=torch.float).repeat([X.shape[0],1,1])\n",
    "    half_tensor = torch.tensor(0.5, dtype=torch.float).repeat([X.shape[0],1,1])\n",
    "    IC_input = prepare_input(X[:,0,:])\n",
    "\n",
    "    # First input is given by the initial condition\n",
    "    comp_input_i = prepare_input(X[:,0,:])\n",
    "    # Iterate along timesteps\n",
    "    for i in range(t_grid.shape[1]-1):\n",
    "        SOLN_I = torch.tensor(X[:,i+1,:])\n",
    "        # First test: composing the model\n",
    "        comp_preds_i = emulator(comp_input_i, one_tensor).detach().numpy()\n",
    "        # comp_preds_i = emulator(comp_input_i).detach().numpy()\n",
    "        preds_dd['FNO'][:,i,:] = comp_preds_i\n",
    "        comp_input_i = prepare_input(comp_preds_i)\n",
    "        errors_i = l2_normalized_error(torch.tensor(comp_preds_i), SOLN_I)\n",
    "        errors_dd['FNO'][:,i] = errors_i\n",
    "\n",
    "        # Second test: prediction from the TDRP\n",
    "        # if time_dep_model:\n",
    "        i_tensor = torch.tensor(t_grid[0,i+1], dtype=torch.float).repeat([X.shape[0],1,1])\n",
    "        preds_k = model(IC_input, i_tensor).detach().numpy() + comp_preds_i\n",
    "        preds_dd['TDRP'][:,i,:] = preds_k\n",
    "        errors_k = l2_normalized_error(torch.tensor(preds_k), SOLN_I)\n",
    "        errors_dd['TDRP'][:,i] = errors_k\n",
    "    # for k,v in errors_dd.items():\n",
    "    #     print(\"{}: {}: {}\".format(k, v.shape, v))\n",
    "    return preds_dd, errors_dd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owen/miniconda3/envs/basis_emulators/lib/python3.7/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/owen/miniconda3/envs/basis_emulators/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "X, t_grid = load_data(DATA_FP)\n",
    "model = load_model(MODEL_FP, torch.device('cpu'))\n",
    "emulator = load_model(BASELINE_FP, torch.device('cpu'))\n",
    "\n",
    "preds_dd, errors_dd = test_TDRP_predictions(X, t_grid, model, emulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_errors(errors_dd, t_grid, title, fp):\n",
    "\n",
    "    n_t_steps = t_grid.shape[1]\n",
    "    x_vals = t_grid.flatten()\n",
    "    plt.figure().patch.set_facecolor('white')\n",
    "    for k, v in errors_dd.items():\n",
    "        print(\"{}: {}: {}\".format(k, v.shape, v))\n",
    "        v_means = np.mean(v, axis=0)\n",
    "        v_stds = np.std(v, axis=0)\n",
    "        plt.plot(x_vals, v_means, label=k, alpha=0.7)\n",
    "        plt.fill_between(x_vals,\n",
    "                            v_means + v_stds,\n",
    "                            v_means - v_stds,\n",
    "                            alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Time step\")\n",
    "    plt.xticks(ticks=np.arange(0, n_t_steps),\n",
    "               labels=make_special_ticks(n_t_steps),\n",
    "              rotation=45,\n",
    "              ha='right',\n",
    "              )\n",
    "    plt.ylabel(\"$L_2$-Normalized Errors\")\n",
    "    # plt.yscale('log')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(fp)\n",
    "    plt.clf()\n",
    "\n",
    "\n",
    "def make_special_ticks(n):\n",
    "    s = \"$t={} \\\\ \\\\to  \\\\ t={}$\"\n",
    "    return [s.format(i, i+1) for i in range(n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TDRP: (99, 20): [[0.01244915 0.01585605 0.02216385 ... 0.43629836 0.49260077 0.88522732]\n",
      " [0.01512696 0.01786236 0.02018981 ... 0.18816753 0.23929786 0.25214812]\n",
      " [0.02022892 0.02951047 0.04045442 ... 0.24535782 0.31154048 0.3391816 ]\n",
      " ...\n",
      " [0.01735274 0.0259438  0.04563707 ... 0.81697395 0.97634489 1.11684803]\n",
      " [0.01499148 0.02382209 0.03644001 ... 0.52357611 0.59917947 0.59614398]\n",
      " [0.0191487  0.0255491  0.03518951 ... 0.90323849 1.00154942 1.06147841]]\n",
      "FNO: (99, 20): [[0.01243497 0.01598123 0.02207848 ... 0.43628975 0.49258585 0.88523006]\n",
      " [0.01481244 0.01785373 0.02005794 ... 0.18829525 0.23918457 0.25206275]\n",
      " [0.02054129 0.03006444 0.04092341 ... 0.24530984 0.31185064 0.33924729]\n",
      " ...\n",
      " [0.017487   0.0261243  0.04565185 ... 0.81696262 0.97635519 1.11683518]\n",
      " [0.01515897 0.02387284 0.03646972 ... 0.52365211 0.59921707 0.59611353]\n",
      " [0.01916176 0.02558736 0.03506258 ... 0.90327206 1.00156956 1.06147459]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fp_time_errors = os.path.join(PLOTS_DIR, 'time_errors.png')\n",
    "errors_dd_i = {k:np.delete(v, [59], axis=0) for k,v in errors_dd.items()}\n",
    "plot_time_errors(errors_dd_i, t_grid[:,:-1], \"FNO vs. TDRP: Test Dataset\", fp_time_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FP = 'second_experiment_results.txt'\n",
    "results_df = pd.read_table(RESULTS_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   learning_rate  modes  ntest  ntrain      test_mse  train_mse  width\n",
      "0        0.00001     16   2000   20000  1.627852e+10   3.581666     64\n",
      "1        0.00001     16   2000   20000  1.627852e+10   3.581113     64\n",
      "2        0.10000     16   2000   20000  1.627852e+10   3.588306     64\n",
      "3        0.00001     16   2000   20000  1.623037e+10   3.581877     64\n",
      "4        0.00001     16   2000   20000  1.623037e+10   3.581964     64\n"
     ]
    }
   ],
   "source": [
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = results_df.sort_values('test_mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    learning_rate  modes  ntest  ntrain      test_mse     train_mse  width\n",
      "32       0.316228     16   2000   20000  1.623037e+10  1.906141e+01     64\n",
      "28       0.000100     16   2000   20000  1.623037e+10  3.259620e+00     64\n",
      "9        0.000010     16   2000   20000  1.623037e+10  3.581531e+00     64\n",
      "66       0.000010     16   2000   20000  1.623037e+10  3.581822e+00     64\n",
      "3        0.000010     16   2000   20000  1.623037e+10  3.581877e+00     64\n",
      "..            ...    ...    ...     ...           ...           ...    ...\n",
      "42       0.316228     16   2000   20000  1.629357e+10  5.259968e+07     64\n",
      "33       0.316228     16   2000   20000           NaN           NaN     64\n",
      "37       0.316228     16   2000   20000           NaN           NaN     64\n",
      "38       0.316228     16   2000   20000           NaN           NaN     64\n",
      "41       0.316228     16   2000   20000           NaN           NaN     64\n",
      "\n",
      "[67 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.49999967865706474"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log10(0.316228)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}