{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bigger-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import scipy\n",
    "from timeit import default_timer\n",
    "\n",
    "import Wavelets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boring-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\"-data_fp\", default=\"/home/owen/projects/fourier_neural_operator/data/2021-03-17_training_Burgers_data_GRF1.mat\")\n",
    "parser.add_argument(\"-plots_dir\", default=\"/home/owen/projects/fourier_neural_operator/experiments/03_use_Haar_DWT/plots\")\n",
    "parser.add_argument(\"-preds_dir\", default=\"/home/owen/projects/fourier_neural_operator/experiments/03_use_Haar_DWT/preds\")\n",
    "# parser.add_argument(\"-results_df\", default=\"/home/owen/projects/fourier_neural_operator/experiments/03_use_Haar_DWT/experiment_results.txt\")\n",
    "\n",
    "parser.add_argument('--subsample_rate', type=int, default=2**3)\n",
    "parser.add_argument('--grid_size', type=int, default=2**13)\n",
    "parser.add_argument('--epochs', type=int, default=500)\n",
    "parser.add_argument('--freq_modes', type=int, default=16)\n",
    "parser.add_argument('--l1_lambda', type=float, default=0.)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "fmt = \"%(asctime)s: %(levelname)s - %(message)s\"\n",
    "time_fmt = '%Y-%m-%d %H:%M:%S'\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=fmt,\n",
    "                    datefmt=time_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "precise-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LpLoss(object):\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "\n",
    "        #Dimension and Lp-norm type are postive\n",
    "        assert d > 0 and p > 0\n",
    "\n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def abs(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        #Assume uniform mesh\n",
    "        h = 1.0 / (x.size()[1] - 1.0)\n",
    "\n",
    "        all_norms = (h**(self.d/self.p))*torch.norm(x.view(num_examples,-1) - y.view(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(all_norms)\n",
    "            else:\n",
    "                return torch.sum(all_norms)\n",
    "\n",
    "        return all_norms\n",
    "\n",
    "    def rel(self, x, y):\n",
    "        num_examples = x.size()[0]\n",
    "\n",
    "        diff_norms = torch.norm(x.reshape(num_examples,-1) - y.reshape(num_examples,-1), self.p, 1)\n",
    "        y_norms = torch.norm(y.reshape(num_examples,-1), self.p, 1)\n",
    "\n",
    "        if self.reduction:\n",
    "            if self.size_average:\n",
    "                return torch.mean(diff_norms/y_norms)\n",
    "            else:\n",
    "                return torch.sum(diff_norms/y_norms)\n",
    "\n",
    "        return diff_norms/y_norms\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        return self.rel(x, y)\n",
    "\n",
    "\n",
    "# reading data\n",
    "class MatReader(object):\n",
    "    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n",
    "        super(MatReader, self).__init__()\n",
    "\n",
    "        self.to_torch = to_torch\n",
    "        self.to_cuda = to_cuda\n",
    "        self.to_float = to_float\n",
    "\n",
    "        self.file_path = file_path\n",
    "\n",
    "        self.data = None\n",
    "        self.old_mat = None\n",
    "        self._load_file()\n",
    "\n",
    "    def _load_file(self):\n",
    "        self.data = scipy.io.loadmat(self.file_path)\n",
    "        self.old_mat = True\n",
    "\n",
    "    def load_file(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self._load_file()\n",
    "\n",
    "    def read_field(self, field):\n",
    "        x = self.data[field]\n",
    "\n",
    "        if not self.old_mat:\n",
    "            x = x[()]\n",
    "            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n",
    "\n",
    "        if self.to_float:\n",
    "            x = x.astype(np.float32)\n",
    "\n",
    "        if self.to_torch:\n",
    "            x = torch.from_numpy(x)\n",
    "\n",
    "            if self.to_cuda:\n",
    "                x = x.cuda()\n",
    "\n",
    "        return x\n",
    "\n",
    "    def set_cuda(self, to_cuda):\n",
    "        self.to_cuda = to_cuda\n",
    "\n",
    "    def set_torch(self, to_torch):\n",
    "        self.to_torch = to_torch\n",
    "\n",
    "    def set_float(self, to_float):\n",
    "        self.to_float = to_float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sharp-anime",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SimpleBlock1d(nn.Module):\n",
    "    def __init__(self, modes, width, level, keep):\n",
    "        super(SimpleBlock1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "\n",
    "        input: the solution of the initial condition and location (a(x), x)\n",
    "        input shape: (batchsize, x=s, c=2)\n",
    "        output: the solution of a later timestep\n",
    "        output shape: (batchsize, x=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes\n",
    "        self.width = width\n",
    "        self.level = level\n",
    "        self.keep = keep\n",
    "        self.fc0 = nn.Linear(2, self.width) # input channel is 2: (a(x), x)\n",
    "\n",
    "        self.wave0 = WaveletBlock1d(self.level, self.width, self.keep)\n",
    "        self.wave1 = WaveletBlock1d(self.level, self.width, self.keep)\n",
    "        self.wave2 = WaveletBlock1d(self.level, self.width, self.keep)\n",
    "        self.wave3 = WaveletBlock1d(self.level, self.width, self.keep)\n",
    "        \n",
    "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        x1 = self.wave0(x)\n",
    "        x2 = self.w0(x)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x1)\n",
    "\n",
    "        x1 = self.wave1(x)\n",
    "        x2 = self.w1(x)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x1)\n",
    "\n",
    "        x1 = self.wave2(x)\n",
    "        x2 = self.w2(x)\n",
    "        x = x1 + x2\n",
    "        x = F.relu(x1)\n",
    "\n",
    "        x1 = self.wave3(x)\n",
    "        x2 = self.w3(x)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = x1.permute(0, 2, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Net1d(nn.Module):\n",
    "    def __init__(self, modes, width, level, keep):\n",
    "        super(Net1d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        A wrapper function\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv1 = SimpleBlock1d(modes, width, level, keep)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "    def count_params(self):\n",
    "        c = 0\n",
    "        for p in self.parameters():\n",
    "            c += reduce(operator.mul, list(p.size()))\n",
    "\n",
    "        return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "tracked-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    # Figure out CUDA\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(\"Running computation on device: {}\".format(device))\n",
    "\n",
    "    ################################################################\n",
    "    #  configurations\n",
    "    ################################################################\n",
    "    ntrain = 100\n",
    "    ntest = 10\n",
    "\n",
    "    # sub = 2**3 #subsampling rate\n",
    "    # h = 2**13 // sub #total grid size divided by the subsampling rate\n",
    "    sub = args.subsample_rate\n",
    "    h = args.grid_size // sub\n",
    "    s = h\n",
    "\n",
    "    batch_size = 10\n",
    "    learning_rate = 0.001\n",
    "\n",
    "    epochs = 4\n",
    "    step_size = 100\n",
    "    gamma = 0.5\n",
    "\n",
    "    modes = 12\n",
    "    width = 4\n",
    "    \n",
    "    level = int(Wavelets.HaarDWT().max_dwt_level(s))\n",
    "    logging.info(\"Using DWT level {}\".format(level))\n",
    "    \n",
    "    keep = int(s)\n",
    "\n",
    "    # results_dd stores trial results and metadata. It will be printed as\n",
    "    # a single line to a text file at args.results_fp\n",
    "    results_dd = {'ntrain': ntrain,\n",
    "                    'ntest': ntest,\n",
    "                    'sub': sub,\n",
    "                    'effective_grid_size': s,\n",
    "                    'epochs': epochs,\n",
    "                    'l1_lambda': args.l1_lambda,\n",
    "                    'modes': modes,\n",
    "                    'width': width}\n",
    "\n",
    "    ################################################################\n",
    "    # read data\n",
    "    ################################################################\n",
    "\n",
    "    # Data is of the shape (number of samples, grid size)\n",
    "    dataloader = MatReader(args.data_fp)\n",
    "    x_data = dataloader.read_field('a')[:,::sub]\n",
    "    y_data = dataloader.read_field('u')[:,::sub]\n",
    "\n",
    "    x_train = x_data[:ntrain,:]\n",
    "    y_train = y_data[:ntrain,:]\n",
    "    x_test = x_data[-ntest:,:]\n",
    "    y_test = y_data[-ntest:,:]\n",
    "    \n",
    "    del x_data\n",
    "    del y_data\n",
    "\n",
    "    # cat the locations information\n",
    "    grid = np.linspace(0, 2*np.pi, s).reshape(1, s, 1)\n",
    "    grid = torch.tensor(grid, dtype=torch.float)\n",
    "    x_train = torch.cat([x_train.reshape(ntrain,s,1), grid.repeat(ntrain,1,1)], dim=2)\n",
    "    x_test = torch.cat([x_test.reshape(ntest,s,1), grid.repeat(ntest,1,1)], dim=2)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # model\n",
    "    model = Net1d(modes, width, level, keep).to(device)\n",
    "#     logging.info(\"Number of model parameters: %i\" % model.count_params())\n",
    "\n",
    "\n",
    "    ################################################################\n",
    "    # training and evaluation\n",
    "    ################################################################\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "    myloss = LpLoss(size_average=False)\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        t1 = default_timer()\n",
    "        train_mse = 0\n",
    "        train_l2 = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            # print(\"TRAINING X SHAPE: {}\".format(x.size()))\n",
    "            # print(\"TRAINING Y SHAPE: {}\".format(y.size()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "\n",
    "            mse = F.mse_loss(out, y, reduction='mean')\n",
    "            # mse.backward()\n",
    "            l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "\n",
    "            # If we specify a l1 regularization on the weights, we add up the\n",
    "            # l1 norms of all of the different weights and add this to the loss.\n",
    "            l1_reg = torch.tensor(0.).to(device)\n",
    "            for param in model.parameters():\n",
    "                l1_reg += torch.norm(param, p=1)\n",
    "\n",
    "            # Our loss function is Lp loss + regulariztion term\n",
    "            loss = l2 + args.l1_lambda * l1_reg\n",
    "\n",
    "            # backprop the gradients, then perform one step of the algorithm.\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            train_mse += mse.item()\n",
    "            train_l2 += l2.item()\n",
    "\n",
    "        scheduler.step()\n",
    "        model.eval()\n",
    "        test_l2 = 0.0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "\n",
    "                out = model(x)\n",
    "                test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "\n",
    "        train_mse /= len(train_loader)\n",
    "        train_l2 /= ntrain\n",
    "        test_l2 /= ntest\n",
    "\n",
    "        t2 = default_timer()\n",
    "        logging.info(\"Epoch: {}, time: {:.2f}, train_mse: {:.4f}, train_l2: {:.4f}, test_l2: {:.4f}, weights_l1: {:.4f}\".format(ep, t2-t1, train_mse, train_l2, test_l2, l1_reg))\n",
    "\n",
    "    torch.save(model, args.model_fp)\n",
    "    logging.info(\"Saved model at {}\".format(args.model_fp))\n",
    "\n",
    "    # Compute training errors:\n",
    "    train_pred = torch.zeros(y_train.shape)\n",
    "    train_y = torch.zeros(y_train.shape)\n",
    "    idx = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            out = model(x)\n",
    "            # print(out.size())\n",
    "            # print(train_pred[idx].size())\n",
    "\n",
    "            train_pred[batch_size*idx: batch_size*(idx + 1)] = out\n",
    "            train_y[batch_size*idx: batch_size*(idx + 1)] = y\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "    train_pred = train_pred.cpu().numpy()\n",
    "    train_y = train_y.cpu().numpy()\n",
    "\n",
    "    results_dd['train_l2_errors'], results_dd['train_l2_normalized_errors'] = find_normalized_errors(train_pred, train_y, 2)\n",
    "    results_dd['train_linf_errors'], results_dd['train_linf_normalized_errors'] = find_normalized_errors(train_pred, train_y, np.inf)\n",
    "\n",
    "\n",
    "    pred = torch.zeros(y_test.shape)\n",
    "    index = 0\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=1, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            test_l2 = 0\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            out = model(x)\n",
    "            pred[index] = out\n",
    "\n",
    "            test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "            logging.info(\"Test index {}, test_l2: {:.4f}\".format(index, test_l2))\n",
    "            index = index + 1\n",
    "\n",
    "    scipy.io.savemat(args.preds_fp, mdict={'pred': pred.cpu().numpy()})\n",
    "\n",
    "\n",
    "\n",
    "    # I'm doing aggregate error reporting in numpy\n",
    "    pred_test = pred.cpu().numpy()\n",
    "    y_test = y_test.cpu().numpy()\n",
    "\n",
    "    results_dd['test_l2_errors'], results_dd['test_l2_normalized_errors'] = find_normalized_errors(pred_test, y_test, 2)\n",
    "    results_dd['test_linf_errors'], results_dd['test_linf_normalized_errors'] = find_normalized_errors(pred_test, y_test, np.inf)\n",
    "    if args.results_fp is not None:\n",
    "        write_result_to_file(args.results_fp, **results_dd)\n",
    "        logging.info(\"Wrote results to {}\".format(args.results_fp))\n",
    "    else:\n",
    "        logging.info(\"No results_fp specified, so here are the results\")\n",
    "        logging.info(results_dd)\n",
    "\n",
    "    logging.info(\"Finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "starting-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IHaarDWT(nn.Module):\n",
    "    \"\"\"Short summary.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    c_filter : pytorch Tensor\n",
    "        Filter to produce c_i coefficients in DWT. Sometimes referred to as h_0.\n",
    "    d_filter : type\n",
    "        Filter to produce d_i coefficients in DWT. Sometimes referred to as h_1.\n",
    "    padder : pytorch nn Module\n",
    "        Appropriately pads odd-length arrays\n",
    "    level : int\n",
    "        Level of the DWT\n",
    "    \"\"\"\n",
    "    def __init__(self, level=1):\n",
    "        super().__init__()\n",
    "        self.c_filter = torch.tensor(np.divide(np.array([1., 1.]),\n",
    "                                                np.sqrt(2)), dtype=torch.float).reshape((1,2,1))\n",
    "        self.d_filter = torch.tensor(np.divide(np.array([1., -1.]),\n",
    "                                                np.sqrt(2)), dtype=torch.float).reshape((1,2,1))\n",
    "        self.filter_len = 2\n",
    "        self.level = level\n",
    "        logging.info(\"Loading IDWT module with level: {}\".format(self.level))\n",
    "\n",
    "    def max_dwt_level(self, data_len):\n",
    "        \"\"\"\n",
    "        This is a function to compute the maximum level DWT that is possible\n",
    "        on a 1D input of length data_len. This formula is copied from\n",
    "        PyWavelets: https://tinyurl.com/y9u7yvbw\n",
    "        \"\"\"\n",
    "        return np.floor(np.log2(data_len / (self.filter_len - 1)))\n",
    "\n",
    "    def unfilter(self, x):\n",
    "        logging.info(\"Unfiltering with input: {}\".format(x.size()))\n",
    "        xlen = x.size()[-1]\n",
    "        batch_num = x.size()[0]\n",
    "        x = x.reshape((batch_num, 2, int(xlen / 2))).permute(0,2,1)\n",
    "        logging.info(\"After reshaping and permuting, shape is {}\".format(x.size()))\n",
    "        c_out = F.conv1d(x, self.c_filter, stride=1)\n",
    "        logging.info(\"C out shape: {}\".format(c_out.size()))\n",
    "        c_out = torch.mm(x, self.c_filter)\n",
    "        d_out = torch.mm(x, self.d_filter)\n",
    "\n",
    "        out = torch.hstack((c_out, d_out)).flatten()\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        # x has shape (1,1,xlen). We need to transform it into (2,xlen / 2)\n",
    "        xlen = x.size()[-1]\n",
    "\n",
    "        if xlen % 2:\n",
    "            raise ValueError(\"Expected even-length input but recieved length {}\".format(xlen))\n",
    "        for l in range(self.level-1, -1, -1):\n",
    "            level_i_arr_idx = int(xlen / (2 ** l))\n",
    "            x_in = x[:,:,:level_i_arr_idx]\n",
    "            x[:,:,:level_i_arr_idx] = self.unfilter(x_in)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "expressed-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletBlock1d(nn.Module):\n",
    "    def __init__(self, level, width, keep):\n",
    "        super(WaveletBlock1d, self).__init__()\n",
    "        self.level = level\n",
    "        self.width = width\n",
    "        self.keep = keep\n",
    "        \n",
    "        self.DWT = Wavelets.HaarDWT(level=level)\n",
    "        self.IDWT = IHaarDWT(level=level)\n",
    "        self.linear_layer = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.weights = nn.Parameter(torch.tensor())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        logging.info(\"WaveletBlock input size: {}\".format(x.size()))\n",
    "        # Do DWT row-by-row\n",
    "        z = torch.zeros(x.size())\n",
    "        xlen = x.size()[-1]\n",
    "        for i, row in enumerate(x.split(1, dim=1)): #Check the axis\n",
    "            out = self.DWT(row)\n",
    "            z[:,i,:self.keep] = out.view(-1, self.keep)\n",
    "        # ok so now z has the DWT coefficients\n",
    "        logging.info(\"Z size: {}\".format(z.size()))\n",
    "        z = self.linear_layer(z)\n",
    "        \n",
    "        out = torch.zeros(z.size())\n",
    "        for i, row in enumerate(z.split(1, dim=1)):\n",
    "            logging.info(\"IDWT Input size: {}\".format(row.size()))\n",
    "            idwt_out = self.IDWT(row)\n",
    "            logging.info(\"IDWT Output size: {}\".format(idwt_out.size()))\n",
    "            out[:, i, :] = idwt_out.view(-1, xlen)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "completed-greene",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-07 16:35:23: INFO - Running computation on device: cpu\n",
      "2021-04-07 16:35:23: INFO - Using DWT level 10\n",
      "2021-04-07 16:35:29: INFO - Loading IDWT module with level: 10\n",
      "2021-04-07 16:35:29: INFO - Loading IDWT module with level: 10\n",
      "2021-04-07 16:35:29: INFO - Loading IDWT module with level: 10\n",
      "2021-04-07 16:35:29: INFO - Loading IDWT module with level: 10\n",
      "2021-04-07 16:35:30: INFO - WaveletBlock input size: torch.Size([10, 4, 1024])\n",
      "2021-04-07 16:35:30: INFO - Z size: torch.Size([10, 4, 1024])\n",
      "2021-04-07 16:35:30: INFO - IDWT Input size: torch.Size([10, 1, 1024])\n",
      "2021-04-07 16:35:30: INFO - Unfiltering with input: torch.Size([10, 1, 2])\n",
      "2021-04-07 16:35:30: INFO - After reshaping and permuting, shape is torch.Size([10, 1, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [1, 2, 1], expected input[10, 1, 2] to have 2 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0c52a01e4312>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWavelets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-6cf819023518>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basis_emulators/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6d5ca942967f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basis_emulators/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6d5ca942967f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwave0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basis_emulators/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-a5c9dff12e2d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IDWT Input size: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0midwt_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIDWT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IDWT Output size: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midwt_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midwt_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/basis_emulators/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-4d7b7a1b76ba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, verbose)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mlevel_i_arr_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlen\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mx_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlevel_i_arr_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlevel_i_arr_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-4d7b7a1b76ba>\u001b[0m in \u001b[0;36munfilter\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlen\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After reshaping and permuting, shape is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C out shape: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 2, 1], expected input[10, 1, 2] to have 2 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "import Wavelets\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-vacation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
